{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9768e9e-58ef-4886-b490-ee8755f9046b",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning â€“ Random Forest Optimization\n",
    "\n",
    "In this section, the best baseline model (Random Forest) is optimized using GridSearchCV.\n",
    "\n",
    "Objective:\n",
    "- Improve ROC-AUC performance\n",
    "- Reduce variance\n",
    "- Improve generalization\n",
    "\n",
    "5-fold cross-validation is used during tuning.\n",
    "ROC-AUC is used as the optimization metric due to the medical nature of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eaa9069-fb65-47d1-af0c-d9840312240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e3a084-682d-4dff-a21b-50429a7317ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/heart_cleaned.csv')\n",
    "\n",
    "X = df.drop('HeartDisease', axis=1)\n",
    "y = df['HeartDisease']\n",
    "\n",
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Load scaler\n",
    "scaler = joblib.load('../models/scaler.pkl')\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc73543-e28b-48ff-904c-d806b1c32cbf",
   "metadata": {},
   "source": [
    "## Baseline Random Forest Performance (Before Tuning)\n",
    "\n",
    "We evaluate the previously trained baseline model to compare improvement after tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ad525c4-a1b2-41f4-8ae2-abb58ded364b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.8695652173913043\n",
      "Baseline ROC-AUC: 0.924079387852702\n"
     ]
    }
   ],
   "source": [
    "# Load baseline model\n",
    "rf_baseline = joblib.load('../models/random_forest.pkl')\n",
    "\n",
    "y_pred_base = rf_baseline.predict(X_test)\n",
    "y_prob_base = rf_baseline.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred_base))\n",
    "print(\"Baseline ROC-AUC:\", roc_auc_score(y_test, y_prob_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc5591a-d25a-4f87-a199-ce683ae71d80",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Space\n",
    "\n",
    "The following parameters are tuned:\n",
    "\n",
    "- n_estimators: Number of trees\n",
    "- max_depth: Controls tree complexity\n",
    "- min_samples_split: Prevents overfitting\n",
    "- min_samples_leaf: Controls leaf size\n",
    "\n",
    "These parameters directly affect bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf739d2-dabb-46a5-a503-2aff19f3a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643545b-cc7b-4d16-a430-68e1cdb0b660",
   "metadata": {},
   "source": [
    "## Running GridSearchCV\n",
    "\n",
    "5-fold cross-validation is used.\n",
    "ROC-AUC is used as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9fce82-6f2f-409a-93f0-e7c10fb24782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best CV ROC-AUC: 0.9284798930869392\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3794a9ec-2424-4924-99ad-8f33c62ee703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuned Random Forest Performance ===\n",
      "Accuracy: 0.8858695652173914\n",
      "ROC-AUC: 0.925872788139646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87        82\n",
      "           1       0.89      0.90      0.90       102\n",
      "\n",
      "    accuracy                           0.89       184\n",
      "   macro avg       0.88      0.88      0.88       184\n",
      "weighted avg       0.89      0.89      0.89       184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_tuned = grid_search.best_estimator_\n",
    "\n",
    "y_pred_tuned = rf_tuned.predict(X_test)\n",
    "y_prob_tuned = rf_tuned.predict_proba(X_test)[:,1]\n",
    "\n",
    "print(\"\\n=== Tuned Random Forest Performance ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tuned))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, y_prob_tuned))\n",
    "print(classification_report(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6835d76b-8fa2-4bfc-9506-1796ce5bb1a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline RF</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.924079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuned RF</td>\n",
       "      <td>0.885870</td>\n",
       "      <td>0.925873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Accuracy   ROC-AUC\n",
       "0  Baseline RF  0.869565  0.924079\n",
       "1     Tuned RF  0.885870  0.925873"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"Baseline RF\", \"Tuned RF\"],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_test, y_pred_base),\n",
    "        accuracy_score(y_test, y_pred_tuned)\n",
    "    ],\n",
    "    \"ROC-AUC\": [\n",
    "        roc_auc_score(y_test, y_prob_base),\n",
    "        roc_auc_score(y_test, y_prob_tuned)\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75709ede-00b3-4da9-9674-77643ed4530d",
   "metadata": {},
   "source": [
    "## Overfitting Assessment\n",
    "\n",
    "To evaluate potential overfitting, we compare:\n",
    "\n",
    "- Cross-validation ROC-AUC\n",
    "- Test ROC-AUC\n",
    "\n",
    "If cross-validation performance is significantly higher than test performance,\n",
    "it may indicate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6d84b0-0c52-421b-8025-a528c2061cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV ROC-AUC: 0.9284798930869392\n",
      "Test ROC-AUC (Tuned): 0.925872788139646\n",
      "Difference (CV - Test): 0.002607104947293215\n"
     ]
    }
   ],
   "source": [
    "print(\"Best CV ROC-AUC:\", grid_search.best_score_)\n",
    "print(\"Test ROC-AUC (Tuned):\", roc_auc_score(y_test, y_prob_tuned))\n",
    "\n",
    "difference = grid_search.best_score_ - roc_auc_score(y_test, y_prob_tuned)\n",
    "\n",
    "print(\"Difference (CV - Test):\", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d985e-ab64-42c6-afcc-8687c234646a",
   "metadata": {},
   "source": [
    "## Tuning Results Interpretation\n",
    "\n",
    "- The tuned model shows a slight improvement in ROC-AUC compared to the baseline model.\n",
    "- Accuracy also increases moderately, indicating improved predictive performance.\n",
    "- The small gain suggests that the baseline Random Forest was already well-optimized.\n",
    "- Hyperparameter tuning primarily helped stabilize and marginally enhance generalization.\n",
    "- The difference between cross-validation and test ROC-AUC is small,\n",
    "  indicating minimal overfitting and good generalization.\n",
    "\n",
    "Given the medical context, even modest improvements in ROC-AUC contribute to better diagnostic reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
